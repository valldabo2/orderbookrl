hpsearch-ppo-rl-parameters:
    env: MarketOrderEnv-v0
    run: PPO
#    resources_per_trial:
#      cpu: 20
#      gpu: 0
    num_samples: 2
    stop:
        time_total_s: 3600 # 60*60*10
    config:
        # Env configuration
        env_config:
          max_sequence_skip: 1500
          random_start: True
          max_episode_time: 3hours

        # Model
        # If true, use the Generalized Advantage Estimator (GAE)
        use_gae: True
        # GAE(lambda) parameter
        lambda:
          grid_search: [0.95, 0.8, 0.6]
        gamma:
          grid_search: [0.9, 0.7]
        # Initial coefficient for KL divergence
        kl_coeff: 0.2
        # Override model config
        model:
          # if Fully connected net
          fcnet_hiddens: [32, 32]
          # Free log std
          free_log_std: False
          # Whether to squash the action output to space range
          squash_to_range: True

          custom_preprocessor: mv
          custom_options:
            fast_macd_l: 120
            slow_macd_l: 240
            ofi_l: 100
            mid_l: 100
        # Which observation filter to apply to the observation
        observation_filter: MeanStdFilter

        clip_rewards: True
        # Optimization
        # Number of timesteps collected for each SGD round
        train_batch_size: 80000
        # Total SGD batch size across all devices for SGD (multi-gpu only)
        sgd_minibatch_size: 1024
        sample_batch_size: 10000
        # Whether to rollout "complete_episodes" or "truncate_episodes"
        batch_mode: truncate_episodes
        # Number of SGD iterations in each outer loop
        num_sgd_iter: 30
        # Stepsize of SGD
        lr: 0.005
        # Coefficient of the value function loss
        vf_loss_coeff: 1.0
        # Coefficient of the entropy regularizer
        entropy_coeff:
          grid_search: [0.01, 0.001]
        # PPO clip parameter
        clip_param:
          grid_search: [0.5, 0.3, 0.1]
        # Target value for KL divergence
        kl_target: 0.01
        # Use the sync samples optimizer instead of the multi-gpu one
        simple_optimizer: True
        # Resources
        num_workers: 3
        # Number of GPUs to use for SGD
        num_gpus: 0
        # Whether to allocate GPUs for workers (if > 0).
        num_gpus_per_worker: 0
        # Whether to allocate CPUs for workers (if > 0).
        num_cpus_per_worker: 2

        grad_clip: 40.0
        #opt_type: adam

        #Whether to use a background thread for sampling (slightly off-policy)
        #sample_async: True
        #synchronize_filters: False

        # Share layers for value function
        vf_share_layers: True

    local_dir: ~/Documents/Hobby/PythonProjects/orderbookrl/logs2/marketorderenv

