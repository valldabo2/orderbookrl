hpsearch-ppo-aggressive:
    env: MarketOrderEnv-v0
    run: PPO
#    resources_per_trial:
#      cpu: 20
#      gpu: 0
    num_samples: 2
    stop:
        time_total_s: 1800 # 60*60*10
    config:
        # Env configuration
        env_config:
          max_sequence_skip: 1500
          random_start: True
          max_episode_time: 2hours

        # Model
        # If true, use the Generalized Advantage Estimator (GAE)
        use_gae: True
        # GAE(lambda) parameter
        lambda: 0.8
        gamma: 0.9
        # Initial coefficient for KL divergence
        kl_coeff: 0.2
        # Override model config
        model:
          # if Fully connected net
          fcnet_hiddens: [32, 32]
          # Free log std
          free_log_std: False
          # Whether to squash the action output to space range
          squash_to_range: True

          custom_preprocessor: mv
          custom_options:
            fast_macd_l: 120
            slow_macd_l: 240
            ofi_l: 100
            mid_l: 100
        # Which observation filter to apply to the observation
        observation_filter: MeanStdFilter

        clip_rewards: True
        # Optimization
        # Number of timesteps collected for each SGD round
        train_batch_size:
          grid_search: [10000, 20000, 40000]
        # Total SGD batch size across all devices for SGD (multi-gpu only)
        sgd_minibatch_size:
          grid_search: [1024, 4096, 10000]
        sample_batch_size: 10000
        # Whether to rollout "complete_episodes" or "truncate_episodes"
        batch_mode: truncate_episodes
        # Number of SGD iterations in each outer loop
        num_sgd_iter:
          grid_search: [5, 10, 30]
        # Stepsize of SGD
        lr:
          grid_search: [0.005, 0.0005]
        # Coefficient of the value function loss
        vf_loss_coeff: 1.0
        # Coefficient of the entropy regularizer
        entropy_coeff: 0.01
        # PPO clip parameter
        clip_param: 0.3
        # Target value for KL divergence
        kl_target: 0.01
        # Use the sync samples optimizer instead of the multi-gpu one
        simple_optimizer: True
        # Resources
        num_workers: 3
        # Number of GPUs to use for SGD
        num_gpus: 0
        # Whether to allocate GPUs for workers (if > 0).
        num_gpus_per_worker: 0
        # Whether to allocate CPUs for workers (if > 0).
        num_cpus_per_worker: 2

        grad_clip: 40.0
        #opt_type: adam

        #Whether to use a background thread for sampling (slightly off-policy)
        #sample_async: True

        # Share layers for value function
        vf_share_layers: True

    local_dir: ~/Documents/Hobby/PythonProjects/orderbookrl/logs/marketorderenv

